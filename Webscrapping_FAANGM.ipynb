{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Web Scraping using Python BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FAANGM Stock data scraping from Yahoo Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\sp2965\\python\\.venv\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sp2965\\python\\.venv\\lib\\site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sp2965\\python\\.venv\\lib\\site-packages (from requests) (3.8)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\sp2965\\python\\.venv\\lib\\site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sp2965\\python\\.venv\\lib\\site-packages (from requests) (2024.7.4)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: BeautifulSoup4 in c:\\users\\sp2965\\python\\.venv\\lib\\site-packages (4.12.3)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\sp2965\\python\\.venv\\lib\\site-packages (from BeautifulSoup4) (2.6)\n"
     ]
    }
   ],
   "source": [
    "!pip3 install BeautifulSoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://finance.yahoo.com/quote/NFLX\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(url) #Make a request to a web page; The get() method sends a GET request to the specified url."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.status_code #The HTTP status code 200 OK means that a request was successful and the server was able to fulfill it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(response.text,'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BeautifulSoup: This is a class from the BeautifulSoup library, which is used to parse HTML and XML documents. It allows you to extract data from HTML tags, navigate the tree structure, and search for specific elements.<br><br>response.text: This is the content of the web page returned by a request made using the requests library.<br><br>response.text contains the HTML content of the page as a string.<br><br>'html.parser': This specifies the parser that BeautifulSoup should use to parse the HTML content. 'html.parser' is the built-in parser in Python that is part of the standard library. It is relatively fast and suitable for most purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Netflix, Inc. (NFLX) Stock Price, News, Quote & History - Yahoo Finance\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "price = soup.find('div',{'class' : 'container yf-mgkamr'}).find_all('fin-streamer')[0].text\n",
    "change = soup.find('div',{'class' : 'container yf-mgkamr'}).find_all('fin-streamer')[1].text\n",
    "percent = soup.find('div',{'class' : 'container yf-mgkamr'}).find_all('fin-streamer')[2].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "soup.find('div', {'class': 'container yf-mgkamr'}): This part of the code searches for the first <div> tag in the HTML with the class D(ib) Mend(20px). The find method returns the first matching element.<br><br>.find_all('fin-streamer'): After finding the <div>, this code searches within that <div> for all occurrences of the <fin-streamer> tags. find_all returns a list of all such tags.<br><br>[0]: This accesses the first <fin-streamer> tag in the list returned by find_all.<br><br>.text: This extracts the text content from the first <fin-streamer> tag. .text retrieves the textual part inside the tag, which is often the main data point you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697.54 +13.70 (+2.00%)\n"
     ]
    }
   ],
   "source": [
    "print(price, change, percent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "mystocks = ['META','NFLX','GOOG','MSFT','AAPL','AMZN']\n",
    "stockData = []\n",
    "\n",
    "def getData(comp):\n",
    "    url =f'https://finance.yahoo.com/quote/{comp}'\n",
    "    req = requests.get(url)\n",
    "    soup = BeautifulSoup(req.text,'html.parser')\n",
    "    stock = {\n",
    "        'comp' : comp,\n",
    "        'price' : soup.find('div',{'class' : 'container yf-mgkamr'}).find_all('fin-streamer')[0].text,\n",
    "        'change' : soup.find('div',{'class' : 'container yf-mgkamr'}).find_all('fin-streamer')[1].text,\n",
    "        'percent' : soup.find('div',{'class' : 'container yf-mgkamr'}).find_all('fin-streamer')[2].text,\n",
    "            }\n",
    "    return stock\n",
    "\n",
    "for i in mystocks:\n",
    "    stockData.append(getData(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'comp': 'META', 'price': '521.12', 'change': '-6.88', 'percent': '(-1.30%)'},\n",
       " {'comp': 'NFLX',\n",
       "  'price': '697.54',\n",
       "  'change': '+13.70',\n",
       "  'percent': '(+2.00%)'},\n",
       " {'comp': 'GOOG', 'price': '167.01', 'change': '+2.51', 'percent': '(+1.53%)'},\n",
       " {'comp': 'MSFT', 'price': '419.49', 'change': '+8.89', 'percent': '(+2.17%)'},\n",
       " {'comp': 'AAPL', 'price': '232.05', 'change': '+5.56', 'percent': '(+2.46%)'},\n",
       " {'comp': 'AMZN', 'price': '174.21', 'change': '+3.41', 'percent': '(+2.00%)'}]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stockData"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Storing Retrieved data in JSON and CSV format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('stockData.json','w') as f:\n",
    "    json.dump(stockData,f)\n",
    "    \n",
    "df = pd.DataFrame(stockData) \n",
    "df.to_csv('stockData.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
